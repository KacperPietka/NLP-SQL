{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch model with 5 modes (for now)\n",
    "*Step 1:* Collect and label data</br>\n",
    "*Step 2:* process data and normalize it!</br>\n",
    "*Step 3:* Convert text to numeric vectors</br>\n",
    "*Step 4:* Train a Lightweight Classifier</br>\n",
    "*Step 5:* Evaluate Performance</br>\n",
    "*Step 6:* Save and Load model to the project</br>\n",
    "\n",
    "### SQL_mode, insight_mode, Comparison_mode, visualization_mode, prediction_mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which period had better transactions?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which period had better expenses?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does conversion rate differ between regions?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does production costs differ between regions?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Compare customers from this quarter to last qu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0              Which period had better transactions?     2\n",
       "1                  Which period had better expenses?     2\n",
       "2   How does conversion rate differ between regions?     2\n",
       "3  How does production costs differ between regions?     2\n",
       "4  Compare customers from this quarter to last qu...     2"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prepare the data and join into one df\n",
    "comparison_df = pd.read_csv(\"training_data_modes/comparison_mode.csv\")\n",
    "insight_df = pd.read_csv(\"training_data_modes/insight_mode.csv\")\n",
    "prediction_df = pd.read_csv(\"training_data_modes/prediction_mode.csv\")\n",
    "sql_df = pd.read_csv(\"training_data_modes/sql_mode.csv\")\n",
    "visualization_df = pd.read_csv(\"training_data_modes/visualization_mode.csv\")\n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat([comparison_df, insight_df, prediction_df, sql_df, visualization_df])\n",
    "X, y = df['text'], df['label']\n",
    "\n",
    "label_to_int = {\n",
    "  \"sql_mode\": 0,\n",
    "  \"insight_mode\": 1,\n",
    "  \"comparison_mode\": 2,\n",
    "  \"visualization_mode\": 3,\n",
    "  \"prediction_mode\": 4\n",
    "}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    row['label'] = label_to_int[row['label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Shuffle the data and split the train test.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = y_train.tolist()\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the embedding model to translate text to vector\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Encode train/test text sets\n",
    "X_train_embeddings = model.encode(X_train)\n",
    "X_test_embeddings = model.encode(X_test)\n",
    "\n",
    "# Convert embeddings to tensors\n",
    "X_train_tensor = torch.tensor(X_train_embeddings, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_embeddings, dtype=torch.float32)\n",
    "\n",
    "# Convert labels to tensors (important!)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "### Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=384, hidden1=128, hidden2=64, output_dim=5):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)          # final layer ‚Üí logits\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit the model\n",
    "model = MLPClassifier(input_dim=384, output_dim=5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optimize the NN\n",
    "for embeddings, labels in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(embeddings)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test Accuracy: 0.7900\n",
      "\n",
      "üìä Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000        38\n",
      "           1      0.662     0.979     0.790        48\n",
      "           2      0.914     0.970     0.941        33\n",
      "           3      0.913     0.955     0.933        44\n",
      "           4      0.771     1.000     0.871        37\n",
      "\n",
      "    accuracy                          0.790       200\n",
      "   macro avg      0.652     0.781     0.707       200\n",
      "weighted avg      0.653     0.790     0.711       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "### Evaluate NN\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# ‚úÖ 1Ô∏è‚É£ Switch model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# ‚úÖ 2Ô∏è‚É£ Disable gradient calculations\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in test_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(embeddings)\n",
    "\n",
    "        # Get predicted class (highest logit)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Store results for later metrics\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# ‚úÖ 3Ô∏è‚É£ Compute accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"‚úÖ Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# ‚úÖ 4Ô∏è‚É£ Detailed performance report\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, digits=3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved successfully: models/mlp_mode_classifier.pt\n"
     ]
    }
   ],
   "source": [
    "# Create a models folder if it doesn't exist\n",
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "\n",
    "# Save the model weights\n",
    "torch.save(model.state_dict(), \"models/mlp_mode_classifier.pt\")\n",
    "\n",
    "print(\"‚úÖ Model saved successfully: models/mlp_mode_classifier.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Label map saved successfully: models/label_map.json\n"
     ]
    }
   ],
   "source": [
    "label_map = {\n",
    "    0: \"sql_mode\",\n",
    "    1: \"insight_mode\",\n",
    "    2: \"comparison_mode\",\n",
    "    3: \"visualization_mode\",\n",
    "    4: \"prediction_mode\"\n",
    "}\n",
    "\n",
    "with open(\"models/label_map.json\", \"w\") as f:\n",
    "    json.dump(label_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model and label map loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load label map\n",
    "with open(\"models/label_map.json\", \"r\") as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "# Initialize model\n",
    "model = MLPClassifier(input_dim=384, hidden1=128, hidden2=64, output_dim=len(label_map))\n",
    "model.load_state_dict(torch.load(\"models/mlp_mode_classifier.pt\", map_location=torch.device(\"cpu\")))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
